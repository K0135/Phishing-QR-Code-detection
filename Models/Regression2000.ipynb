{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfa1b39-3bd1-4b13-9f34-419c6597661a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "import shap\n",
    "import whois\n",
    "from __future__ import print_function\n",
    "import pyzbar.pyzbar as pyzbar\n",
    "import cv2\n",
    "import re\n",
    "import time\n",
    "from sklearn import tree\n",
    "import pydotplus as pdp\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as pltimg\n",
    "\n",
    "def qrcoderead():\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    cap.set(3,640)\n",
    "    cap.set(4,480)\n",
    "    #160.0 x 120.0\n",
    "    #176.0 x 144.0\n",
    "    #320.0 x 240.0\n",
    "    #352.0 x 288.0\n",
    "    #640.0 x 480.0\n",
    "    #1024.0 x 768.0\n",
    "    #1280.0 x 1024.0\n",
    "    time.sleep(2)\n",
    "\n",
    "    def decode(im) : \n",
    "        # Find barcodes and QR codes\n",
    "        decodedObjects = pyzbar.decode(im) \n",
    "        return decodedObjects\n",
    "\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "    while(cap.isOpened()):\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        # Our operations on the frame come here\n",
    "        im = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        decodedObjects = decode(im)\n",
    "\n",
    "        for decodedObject in decodedObjects: \n",
    "            points = decodedObject.polygon\n",
    "\n",
    "            # If the points do not form a quad, find convex hull\n",
    "            if len(points) > 4 : \n",
    "              hull = cv2.convexHull(np.array([point for point in points], dtype=np.float32))\n",
    "              hull = list(map(tuple, np.squeeze(hull)))\n",
    "            else : \n",
    "              hull = points;\n",
    "\n",
    "            # Number of points in the convex hull\n",
    "            n = len(hull)     \n",
    "            # Draw the convext hull\n",
    "            for j in range(0,n):\n",
    "              cv2.line(frame, hull[j], hull[ (j+1) % n], (255,0,0), 3)\n",
    "\n",
    "            x = decodedObject.rect.left\n",
    "            y = decodedObject.rect.top\n",
    "            barCode = str(decodedObject.data)\n",
    "            cv2.putText(frame, barCode, (x, y), font, 1, (0,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('frame',frame)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key & 0xFF == ord('q'):\n",
    "            break\n",
    "        elif key & 0xFF == ord('s'): # wait for 's' key to save \n",
    "            cv2.imwrite('Capture.png', frame)     \n",
    "\n",
    "    # When everything done, release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return decodedObject.data\n",
    "\n",
    "#Above function was mostly obtained from \"https://github.com/cuicaihao/Webcam_QR_Detector\". Alterations were made for this poject but the general code is still the same.\n",
    "\n",
    "dftest = pd.read_csv(r\"C:\\Users\\bulle_000\\Desktop\\send help\\dataset.csv\")\n",
    "dftest = dftest.head(1)\n",
    "z = [\"URLURL_Length\", \"Shortining_Service\", \"having_At_Symbol\", \"double_slash_redirecting\", \"Prefix_Suffix\", \"SSLfinal_State\", \"HTTPS_token\", \"web_traffic\" ,\"age_of_domain\", \"Domain_registeration_length\", \"having_IPhaving_IP_Address\", \"Abnormal_URL\", \"URL_of_Anchor\"]\n",
    "dftest = dftest[z]\n",
    "\n",
    "def test_len(x):\n",
    "    if len(x) < 54:\n",
    "        dftest.at[0,\"URLURL_Length\"] = 1\n",
    "    elif len(x) < 76:\n",
    "        dftest.at[0,\"URLURL_Length\"] = 0\n",
    "    else:\n",
    "        dftest.at[0,\"URLURL_Length\"] = -1\n",
    "        \n",
    "\n",
    "def url_short(x):\n",
    "    if \"bit.ly\" in x:\n",
    "        dftest.at[0,\"Shortining_Service\"] = -1\n",
    "    elif \"tinyurl.com\" in x:\n",
    "        dftest.at[0,\"Shortining_Service\"] = -1\n",
    "    else:\n",
    "        dftest.at[0,\"Shortining_Service\"] = 1\n",
    "\n",
    "def has_at(x):\n",
    "    if \"@\" in x:\n",
    "        dftest.at[0,\"having_At_Symbol\"] = -1\n",
    "    else:\n",
    "        dftest.at[0,\"having_At_Symbol\"] = 1\n",
    "\n",
    "def redirect(x):\n",
    "    y = x[7:]\n",
    "    if \"//\" in y:\n",
    "        dftest.at[0,\"double_slash_redirecting\"] = -1\n",
    "    else:\n",
    "        dftest.at[0,\"double_slash_redirecting\"] = 1\n",
    "\n",
    "def prefix(x):\n",
    "    if \"-\" in x:\n",
    "        dftest.at[0,\"Prefix_Suffix\"] = -1\n",
    "    else:\n",
    "        dftest.at[0,\"Prefix_Suffix\"] = 1\n",
    "\n",
    "def https(x):\n",
    "    if \"https\" in x[:10]:\n",
    "        dftest.at[0,\"SSLfinal_State\"] = 1\n",
    "    elif \"http\" in x[:10]: \n",
    "        dftest.at[0,\"SSLfinal_State\"] = -1\n",
    "    else:\n",
    "        dftest.at[0,\"SSLfinal_State\"] = 0\n",
    "\n",
    "def httpstoken(x):\n",
    "    if \"https\" in x[5:]:\n",
    "        dftest.at[0,\"HTTPS_token\"] = -1\n",
    "    else:\n",
    "        dftest.at[0,\"HTTPS_token\"] = 1\n",
    "\n",
    "def get_rank(x):\n",
    "    import requests\n",
    "    import sys\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re\n",
    "    import validators\n",
    "\n",
    "\n",
    "    alexa_base_url = 'https://alexa.com/siteinfo/'\n",
    "    site_name = x\n",
    "\n",
    "\n",
    "    def is_valid_domain(site_name):\n",
    "        if validators.domain(site_name):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    url_for_rank = alexa_base_url + site_name\n",
    "\n",
    "    # Request formatted url for rank(s)\n",
    "    page = requests.get(url_for_rank)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    # get ranks text in a list\n",
    "    country_ranks = soup.find_all('div', id='CountryRank')\n",
    "\n",
    "    # select the data with class='rank-global' and the class='data'\n",
    "    global_rank = soup.select('.rank-global .data')\n",
    "\n",
    "    # Display Global rank safely\n",
    "    try:\n",
    "        match = re.search(r'[\\d,]+', global_rank[0].text.strip())\n",
    "    except:\n",
    "        return \"none\"\n",
    "    return match.group()    \n",
    "\n",
    "def global_rank(x):\n",
    "    y = get_rank(x)\n",
    "    if y == \"none\":\n",
    "        dftest.at[0,\"web_traffic\"] = -1\n",
    "        return\n",
    "    y = re.sub(\"[^0-9]\", \"\",str(y))\n",
    "    if int(y) < 100000:\n",
    "        dftest.at[0,\"web_traffic\"] = 1\n",
    "    else:\n",
    "        dftest.at[0,\"web_traffic\"] = 0\n",
    "\n",
    "def is_registered(domain_name):\n",
    "    try:\n",
    "        w = whois.whois(domain_name)\n",
    "    except Exception:\n",
    "        return False\n",
    "    else:\n",
    "        return bool(w.domain_name)\n",
    "def domain_age(x):\n",
    "    import re\n",
    "    z = 0\n",
    "    from datetime import date\n",
    "    today = date.today()\n",
    "    if is_registered(x):\n",
    "        y = whois_info.creation_date\n",
    "        y = re.sub(\"[^0-9]\", \"\",str(y))\n",
    "        y = y[:6]\n",
    "        time = re.sub(\"[^0-9]\", \"\", str(today))\n",
    "        time = time[:6]\n",
    "        if y == \"\":\n",
    "            return z\n",
    "        tpass = int(time) - int(y)\n",
    "    else: \n",
    "        return z\n",
    "    return tpass\n",
    "def domainpostive(x):\n",
    "    tp = domain_age(x)\n",
    "    if tp > 5:\n",
    "        dftest.at[0,\"age_of_domain\"] = 1\n",
    "    else:\n",
    "        dftest.at[0,\"age_of_domain\"] = -1\n",
    "        \n",
    "def reg_len(x):\n",
    "    z=0\n",
    "    from datetime import date\n",
    "    today = date.today()\n",
    "    if is_registered(x):\n",
    "        y = whois_info.expiration_date\n",
    "        y = re.sub(\"[^0-9]\", \"\",str(y))\n",
    "        y = y[:6]\n",
    "        time = re.sub(\"[^0-9]\", \"\", str(today))\n",
    "        time = time[:6]\n",
    "        if y == \"\":\n",
    "            return z\n",
    "        time_till = int(y) - int(time)\n",
    "    else:\n",
    "        return z\n",
    "    return time_till\n",
    "\n",
    "def reg_len_change(x):\n",
    "    y = reg_len(x)\n",
    "    if y < 100:\n",
    "        dftest.at[0,\"Domain_registeration_length\"] = -1\n",
    "    else: \n",
    "        dftest.at[0,\"Domain_registeration_length\"] = 1\n",
    "\n",
    "def ipad(x):\n",
    "\n",
    "    x = x[7:15]\n",
    "    z = re.sub(\"[^0-9]\", \"\", x)\n",
    "    if len(z) > 5:\n",
    "        dftest.at[0,\"having_IPhaving_IP_Address\"] = -1\n",
    "    else: \n",
    "        dftest.at[0,\"having_IPhaving_IP_Address\"] = 1\n",
    "\n",
    "def abnormal(x):\n",
    "    y = \"dfajksjdlasdl;ajsd;l\"\n",
    "    if is_registered(x):\n",
    "        y = str(whois_info.domain_name)\n",
    "        y = y.lower()\n",
    "    if y in x:\n",
    "        dftest.at[0,\"Abnormal_URL\"] = 1\n",
    "    else:\n",
    "        dftest.at[0,\"Abnormal_URL\"] = -1\n",
    "\n",
    "def url_anchor(x):\n",
    "    try:\n",
    "        if is_registered(x):        \n",
    "            domain = whois_info.domain_name\n",
    "        response = requests.get(x)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        liss = list()\n",
    "        count = 0\n",
    "        countbad = 0\n",
    "        for link in soup.findAll('a'):\n",
    "            liss.append(link.get('href'))\n",
    "        for i in range(len(liss)):\n",
    "            string = liss[i]\n",
    "            try:\n",
    "                if \"http\" in string:\n",
    "                    if x in string:\n",
    "                        count = count\n",
    "                    elif domain in string:\n",
    "                        count = count\n",
    "                    else:\n",
    "                        countbad += 1\n",
    "            except:\n",
    "                count -= 1\n",
    "            count += 1\n",
    "        if count == 0:\n",
    "            dftest.at[0, \"URL_of_Anchor\"] = 0\n",
    "            return 1\n",
    "        returnvalue = countbad/count\n",
    "        if returnvalue > 0.67:\n",
    "            dftest.at[0, \"URL_of_Anchor\"] = -1\n",
    "        elif returnvalue > 0.31:\n",
    "             dftest.at[0, \"URL_of_Anchor\"] = 0\n",
    "        else:\n",
    "             dftest.at[0, \"URL_of_Anchor\"] = 1\n",
    "    except:\n",
    "        dftest.at[0, \"URL_of_Anchor\"] = 0\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\bulle_000\\Desktop\\send help\\finaldata.csv\")\n",
    "df = df[:2000] \n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "z = [\"URLURL_Length\", \"Shortining_Service\", \"having_At_Symbol\", \"double_slash_redirecting\", \"Prefix_Suffix\", \"SSLfinal_State\", \"HTTPS_token\", \"web_traffic\" ,\"age_of_domain\", \"Domain_registeration_length\", \"having_IPhaving_IP_Address\", \"Abnormal_URL\", \"URL_of_Anchor\"]\n",
    "X = df[z] \n",
    "y = df[\"Label\"]\n",
    "X_test = X[1750:]\n",
    "y_test = y[1750:]\n",
    "X_train = X[:1750]\n",
    "y_train = y[:1750]\n",
    "\n",
    "dtree = RandomForestRegressor(n_estimators=20, random_state=0)\n",
    "dtree = dtree.fit(X_train, y_train)\n",
    "\n",
    "from sklearn import metrics\n",
    "y_pred = dtree.predict(X_test)\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "def testqr(x):\n",
    "    if is_registered(x):    \n",
    "        whois_info = whois.whois(x)\n",
    "    test_len(x)\n",
    "    url_short(x)\n",
    "    has_at(x)\n",
    "    redirect(x)\n",
    "    prefix(x)\n",
    "    https(x)\n",
    "    httpstoken(x)\n",
    "    domainpostive(x)\n",
    "    global_rank(x)\n",
    "    reg_len_change(x)\n",
    "    ipad(x)\n",
    "    abnormal(x)\n",
    "    url_anchor(x)\n",
    "    y = dtree.predict(dftest)\n",
    "    if y <-0.5:\n",
    "        print(\"Probobly Phising, The closer to -1 the higher the chance!\")\n",
    "    elif y < 0:\n",
    "        print(\"Possibly Phising, The closer to -1 the higher the chance!\")\n",
    "    elif y < 0.5:\n",
    "        print(\"Probobly not, but still possibly Phising, the closer to 1 the safer you are!\")\n",
    "    else:\n",
    "        print(\"Almost defenitely not Phising, the closer to 1 the safer you are!\")\n",
    "    print (y)\n",
    "\n",
    "def main():\n",
    "    x = qrcoderead()\n",
    "    x = str(x)\n",
    "    x = x[2:]\n",
    "    x = x[:-1]\n",
    "    if is_registered(x):    \n",
    "        global whois_info \n",
    "        whois_info = whois.whois(x)\n",
    "    test_len(x)\n",
    "    url_short(x)\n",
    "    has_at(x)\n",
    "    redirect(x)\n",
    "    prefix(x)\n",
    "    https(x)\n",
    "    httpstoken(x)\n",
    "    domainpostive(x)\n",
    "    global_rank(x)\n",
    "    reg_len_change(x)\n",
    "    ipad(x)\n",
    "    abnormal(x)\n",
    "    url_anchor(x)\n",
    "    y = dtree.predict(dftest)\n",
    "    if y <-5:\n",
    "        print(\"Probobly Phising, The closer to -1 the higher the chance!\")\n",
    "    elif y < 0:\n",
    "        print(\"Possibly Phising, The closer to -1 the higher the chance!\")\n",
    "    elif y < 0.5:\n",
    "        print(\"Probobly not, but still possibly Phising, the closer to 1 the safer you are!\")\n",
    "    else:\n",
    "        print(\"Almost defenitely not Phising, the closer to 1 the safer you are!\")\n",
    "    print (y)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    %%time\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
